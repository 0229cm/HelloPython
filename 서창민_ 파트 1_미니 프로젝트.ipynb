{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---   \n",
    "\n",
    "# Part 1. Mini Project\n",
    "\n",
    "### 비즈니스 문제를 해결하기 위해 데이터로 어떻게 접근, 해결할지 생각해보는 문제\n",
    "    - Q. 1~3 문제 : 잔존율 증가를 위한 비즈니스 문제해결 \n",
    "    - Q. 4~6 문제 : 금융권 VIP 고객의 연간 소비금액을 예측하기 위한 모델 구축 작업\n",
    "    - Q. 7~8 문제 : 유저 세분화 및 그룹핑을 위한 데이터 분석 작업\n",
    "\n",
    "\n",
    "### 머신러닝의 학습과정 및 활용에 대한 이해를 확인하는 문제\n",
    "    - Q. 9 문제 : 손실함수의 필요성과 개념에 대한 이해\n",
    "    - Q. 10~11 문제 : Gradient Descent의 과정과 SGD, MGD 처리 방식의 이해\n",
    "    - Q. 12-13 문제 : 오버피팅 개념 및 해결방법에 대한 이해\n",
    "    - Q. 14-15 문제 : CNN 및 RNN 의 동작원리에 대한 이해와 활용\n",
    "\n",
    "\n",
    "- 작성자: 송훈화 감수자\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q. 1~3. 잔존율 증가를 위한 비즈니스 문제해결 방안 마련\n",
    "\n",
    "### 배경\n",
    "다음과 같은 비즈니스 문제가 있다고 하자. \n",
    "현재 앱서비스의 잔존율이 정체되어 있는 상황이며 재이용자의 증가가 필수적인 상황이다. 여기서 잔존율이란 서비스를 이용하던 기존 유저가 시간이 흘러도 지속적으로 이용하고 있는 정도를 의미한다. \n",
    "\n",
    "\n",
    "### 목표\n",
    "분석가에게 주어진 역할은 사내에 수집된 데이터를 추출해 잔존율을 높일 수 있는 방안을 유관팀에 공유하는 것이다. 유관팀은 개별 유저별로 잔존 여부를 예측할 수 있다면, 이를 근거로 개인화된 타깃팅을 진행할 수 있을 것이다. 분석가는 데이터를 근거로 유저들의 잔존 여부를 예측할 수 있는 모델을 구축하고자 한다. 즉 분석 목표는\n",
    "   - 잔존 vs 비잔존 그룹간의 유저 행동 패턴을 이해하고,\n",
    "   - 개별 유저의 잔존 여부(Y/N)를 예측할 수 있는 모델을 만드는 것이다.\n",
    "\n",
    "위에 주어진 목표를 달성하기 위해 어떤 접근방법을 활용해야할지 각 단계별로 기술해보자.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 수집: 어떤 데이터를 수집/추출할 것인가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "어떠한 이유때문에 유저들이 이탈하는지에 대한 가설을 세우고. 이에대해서 알아보기 위해 데이터들을 비교해야한다. 이러한 과정에서 변수들간의 비교그래프를 그려 볼 수 있고 변수들간의 상관관계를 따져볼 수 있다.\n",
    "\n",
    "잔존율은 정체되고 재이용자의 수를 증가시켜야 하는 상황이므로 잔존그룹과 비잔존 그룹의 부분 데이터를 선택하고 선택한 변수들을 병합하여 파생변수를 만들어야한다.\n",
    "\n",
    "이 후, 가설에 대한 검증을 하고 가설이 검증되거나 검증될 확률이 높은 결과를 도출해낸다면 그에대한 데이터를 분석해야한다. 만약 유의미한 결과를 얻지 못한다면 다시 가설을 세우고 다른 변수를 추가하는 방법을 쓸 수 있다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 탐색적 데이터 분석: 유저의 행동패턴 이해를 위해 데이터 탐색을 어떻게 할 것인가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "유저들의 행동패턴 이해를 위해서 잔존유저, 비잔존 유저들의 각각의 변수들을 뽑아서 변수들간의 관계나 특성을 분석하고 기술 통계량 계산과 여러가지 그래프를 활용해 볼 수 있다.\n",
    "이 데이터들에는 수 많은 변수들이 존재할 것이므로 이에대한 데이터를 인식 가능한 수준으로 요약해야한다. 정해진 알고리즘을 이용해서 데이터 정보를 찾아낼 수 있는데 이 알고리즘을 이용해서 데이터들의 변수와 관측치 간 관계를 확인해 볼 수 있다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 모형 적합: 어떤 예측모형을 이용해 잔존 여부를 예측할 것인가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "향후 잔존율에 대한 예측을 하는것이기 때문에 로지스틱 회귀분석을 이용하여\n",
    "종속변수와 독립변수를 설정하고 이에대한 예측값을 알아 볼 수 있다. 이 외에도 랜덤\n",
    "포레스트 기법이나 SVM 을 잔존여부 예측에 이용할 수도 있다.\n",
    "\n",
    "모델마다 성능이 다르게 나올 것이기 때문에 가장 적합한 모델을 사용해야하며 이\n",
    "과정에서 목적에 맞는 feature 를 합리적으로 만들어야한다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q. 4~6. 금융권 VIP 고객의 연간 소비금액을 예측하기 위한 모델 구축 작업\n",
    "\n",
    "### 배경 및 목표\n",
    "금융권의 한 기업에서 VIP 고객들의 연간 소비금액(단위: 원)을 예측하기 위한 모델을 만들고 있다. 영업팀은 이 예측모델을 새로운 고객관리시스템에 도입하고자 준비하고 있다. 분석가의 목표는 기존 VIP 고객들의 소비금액을 기반으로 새로운 VIP 고객의 연간 소비금액(단위: 원)을 예측하는 것이다.\n",
    "\n",
    "### 데이터셋\n",
    "분석가에게 주어진 데이터셋의 컬럼은 아래와 같다. \n",
    "\n",
    "- 고객아이디(숫자형)\n",
    "- 연봉(숫자형)\n",
    "- 주소(문자) \n",
    "- 연간 소비금액 (숫자형, 단위: 원)\n",
    "- 성별(문자)\n",
    "- 계좌 잔고금액(숫자형, 단위: 원)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 입력 데이터(X, features)로 적절한 변수와 타깃 데이터(y, target, label)로 적절한 변수는 각각 무엇일까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "입력데이터 X 들로 타깃 데이터 Y 를 예측하고 싶은 문제이기 때문에 Y 는 연간 소비금액이 되어야 한다.\n",
    "\n",
    "입력 데이터는 고객의 연봉, 계좌 잔고금액을 사용할 수 있다.\n",
    "\n",
    "고객아이디, 주소, 성별은 입력데이터로 부적절하다고 볼 수 있다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 지도학습(회귀), 지도학습(분류), 비지도학습, 강화학습 중에 어떤 모델을 적용할 것인가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "입력 데이터 X 와 타겟값 Y 를 알고있는 데이터를 학습하여 이들의 관계를 모델링 하는\n",
    "학습방법은 지도학습(회귀)이다.\n",
    "\n",
    "이 문제에서는 비지도학습처럼 타겟값 Y 가 없는 입력데이터 X 만을 학습하는 것이\n",
    "아니기 때문에 지도학습을 사용해야한다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 생성된 모델이 학습 데이터에서는 성능이 높았으나 테스트 데이터에서 성능이 낮았다. 추정되는 이유는 무엇인가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "test set 에서 실제로는 타겟값이 있지만 없다고 가정을 한다. 왜냐하면 Y 가 없이 X만 관측될 데이터이기 때문이다.\n",
    "X 만 관측되었다고 생각하고 이것을 모델에 넣어 결과값을 도출한 뒤, 실제로 있는 타겟값과 비교를 해서 실제 성능이 좋은지 아닌지를 판별하기 위해 소모되기 때문이다.\n",
    "그렇기 때문에 테스트셋에서는 성능이 안좋게 나올지라도 실제 학습데이터 에서는 성능이 높게 나올 수 있다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7~8.  유저 세분화 및 그룹핑을 위한 데이터 분석 작업\n",
    "\n",
    "### 배경 및 목표\n",
    "전체 소비자를 대상으로 한 마케팅 비용 및 리소스가 매우 큰 것으로 나타남에 따라, 전체 소비자를 세분화하여 그룹을 만든후 특정 그룹을 대상으로 마케팅을 진행하고자 한다. 분석가의 역할은 주어진 아래 데이터셋을 가지고 소비자를 세분화된 결과를 마케팅팀에 공유하는 것이다.\n",
    "\n",
    "### 데이터셋\n",
    "\n",
    "- 유저 아이디(숫자형)\n",
    "- 방문당 평균 결제횟수 (숫자형)\n",
    "- 방문당 공유 횟수 (숫자형)\n",
    "- 재방문율 (숫자형)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 지도학습(회귀), 지도학습(분류), 비지도학습, 강화학습 중에 어떤 모델을 적용할 것인가? 이유는 무엇인가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "비지도학습을 적용해야하며 여기서 사용될 수 있는 X 는 방문당 평균 결제횟수, 방문당 공유 횟수, 재방문율이 될 수 있다.\n",
    "\n",
    "지도학습과는 다르게 Y 가 없는 X 만을 학습하는 방법이며, 입력데이터에 내제되어 있는 특성을 찾기위한 용도가 비지도학습이기 때문이다.\n",
    "\n",
    "이 문제에서는 4가지의 입력데이터의 내제되어 있는 특성을 사용하는것이기 때문에 비지도학습을 적용해야한다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 만약 위 변수를 가지고 명확히 소비자가 세분화되지 않는다면 어떻게 해결하는 것이 좋을까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "군집화(clustering) 를 사용하는 것이다.\n",
    "타겟 Y 가 없기때문에 X 들의 입력변수만으로 이 데이터에 가장 최적화된 구조를 찾는것이다. 이 때 각각의 클러스터들을 구분 할 수 있게되며 여기서 나온 X 들의 ID 를 얻을 수 있으며 이를 모델로 사용 할 수 있다. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 9. 머신러닝에서 손실함수는 모델의 학습과정에서 매우 중요한 역할을 한다. 이 역할에 대해 상세히 기술해보자. 그리고 회귀, 분류 각 문제별로 대표적인 손실함수를 예로 들어보자.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "학습 알고리즘이 작동하게끔 만드는 원동력이며 손실함수의 값을 줄여나가는 과정이 곧 모델을 학습하는 과정이다.\n",
    "\n",
    "여기서 손실이란 실제 데이터에서 관측된 결과와 모델에 의해 생성된 결과의 차이이다.\n",
    "손실이 작으면 작을수록 모델의 성능이 좋다.\n",
    "손실을 함수로 정의하는 이유는 수리적으로 계산하기 위해서이다.\n",
    "\n",
    "분류모델의 손실함수는 교차 엔트로피 회귀모델의 손실함수는 평균 제곱 오차가 있다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10~11. Gradient Descent의 과정과 SGD, MGD 처리 방식의 이해\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Gradient Descent 는 손실함수를 최소화하는 Weight을 찾아내기 위해 점진적으로 진행하는 최적화 방법중 하나이다. 경사하강법을 통해 손실함수 값을 최소화하는 과정을 간단히 기술해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "loss function 의 값이 줄어들도록 weight 값을 조금씩 바꿔야한다.\n",
    "\n",
    "x 축을 weight 로 정의하고 y 축을 loss 라 정의했을 때 loss 를 w 로 미분하고, 미분값이 가리키는 방향의 반대방향으로 아주 조금씩 weight를 바꿔나가면 loss 를 감소시킬 수 있다.\n",
    "\n",
    "원하는 weight 를 찾기 위해서는 어떻게 하는가?\n",
    "\n",
    "아무것도 모르는 상태에서의 weight 의 초기값은 모르기때문에 random 한 값으로 시작한다.\n",
    "이를 random initialization 이라 한다.\n",
    "\n",
    "예시를 들자면 산 위에서 눈을 가리고 제일 낮은곳으로 가는 예를 들 수 있다.\n",
    "현재의 위치에서 내려가는 방향으로 천천히 내려가다보면 언젠가 제일 낮은점에 도착할 수 있다는 예시이다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. 많은 데이터에 대해 한번에 Gradient Descent 를 적용했을 때(즉 Batch 처리) 학습에 시간이 오래 걸리는 문제가 발생한다. 따라서 Stochastic, Mini-batch Gradient Descent 과 같은 방법들을 사용하는데, 각 방법들에 대해 기술해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "stocahastic 는 데이터 중 data 중 1개만 뽑고 그 1개에 대해서 loss 를 계산하고 그 loss 가 전체의 loss 와 비슷할거라 가정하고 학습하며 weight 를 바꿔간다는 내용이다.\n",
    "\n",
    "mini-batch gradient descent 는 batch/stochastic 의 중간형태이며 data 중 n개를 뽑고 그 n개의 data에 대한 loss 를 계산하여 다 더한 뒤 이를 이용하여 미분해서 학습하겠다는 내용이다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12~13. 오버피팅 개념 및 해결방법에 대한 이해\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. 머신러닝 모델을 구축하기 위해 전체 데이터를 학습셋, 검증셋, 테스트셋으로 분리시키는데 이렇게 분리시키는 목은 무엇이며, 각 데이터셋의 이용 목적을 기술해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "training set 은 학습에 사용하는 data 이고\n",
    "validation set 은 학습에 사용하지 않고, hyper parameter tuning 에 사용하는 data이다.\n",
    "test set 은 학습이 완전히 끝난 후에 model 을 평가하기 위한 data이다.\n",
    "\n",
    "이들을 분리시키는 목적은 모델의 성능을 잘 평가하기 위해서이다. \n",
    "test set 에서는 처음 보는 데이터에 대해서 평가를 해야하고 이러한 이유 때문에 training set, validation set, test set 을 분리한다. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.  과적합(Overftting)이 발생했을 때 이를 해결할 수 있는 방안은 무엇이 있을지 작성해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "첫번째로 data 의 양을 늘리는 방법이있다.\n",
    "\n",
    "둘째로는 regularization 방법이 있다.\n",
    "정규화라 하며 weight 값을 너무 크지않게 만들어주는 방법이며\n",
    "이에는 l1/l2 regularization, dropout, batch normaliaztion 이 있다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 14~15. CNN 및  RNN 의 동작원리에 대한 이해와 활용\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 14. 주로 이미지 인식을 위해 가장 널리 알려진 CNN(Convolutional Neural Network)의 학습과정에 대해 간단히 기술해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "이미지 인식에 가장 많이 사용된다.\n",
    "일반적으로 convolution layer, pooling layer, fully-connected layer 로 구성되어 있으며 사진을 구분할 때 convolution layer 에서는 feature 를 추출하고 pooling layer 에서는 추출된 feature 들을 모아준다. fully-connected layer 에서는 최종적으로 모인 feature를 가지고 넣은 사진이 무엇인지 판단해준다.\n",
    "\n",
    "이미지를 각 tile 로 쪼개서 tile 의 특정 feature 를 추출하며 모든 tile 의 총합 점수를 계산하여 판단해낸다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. RNN(Recurrent Neural Network)의 개념과 대표적인 문제점, 해결방법에 대해 기술해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "sequence 가 길어지면 성능의 저하, 학습의 어려움, 오래전 입력된 값에 대해서는 잘 기억하지 못하는 문제점들이 존재한다.\n",
    "\n",
    "이를 해결하기 위해 만들어진 network 들은 lstm, gru 가 있다.\n",
    "lstm 은 long short term memory 이며\n",
    "gru 는 gated recurrent unit 이다.\n",
    "\n",
    "long term dependency 를 잘 해결하고 학습이 잘 되게 도와주는 역할을 한다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
