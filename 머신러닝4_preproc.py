# -*- coding: utf-8 -*-
"""머신러닝4-preproc.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BYYbi2mVQZHmwtRNV4lEB-VKq0L9deWn
"""

from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

from sklearn.model_selection import train_test_split
import numpy as np
from sklearn.model_selection import cross_val_score
import pandas as pd
import matplotlib.pyplot as plt

"""# 데이터전처리 
* 머신러닝 알고리즘을 익히는 것 못지 않게
데이터 전처리 역시 중요한 과정 중에 하나
* 무엇보다 머신러닝 알고리즘을 적용하기 전에
제이터에 대해 미리 처리해야 하는 기본사항이 존재

* 결측치 처리 
  + NaN, Null은 허용되지 않음
* 원핫인코딩 : 머신러닝 알고리즘들은 문자열값을 데이터의 입력값을 허용하지 않음
  + 따라서, 모든 문자열값은 이코딩해서 숫자형으로 변환해둬야 함
  + 한편, 텍스트 데이터들은 벡터화해서 처리
  + 머신러닝을 위한 인코딩은 레이블인코딩과 원핫인코딩등이 있음


# 레이블인코딩 label encoding
* 범주형값을 숫자값으로 변환하는것을 의미
"""

from sklearn.preprocessing import LabelEncoder

items = ['티비','냉장고','가스렌지','에어콘','컴퓨터']

encoder = LabelEncoder()
encoder.fit(items)
labels = encoder.transform(items)

print(labels)             # 변환된 인코딩 값
print(encoder.classes_)   # 인코딩 문자열 순서

"""# LabelEncoder 사용시 문제점
* 문자열값을 숫자형으로 변환시켰을때 발생할 수 있는 문제는  각 값의 대소 관게를 통해 중요도 여부가 존재할 수 있음
* 즉, 인코딩 값에 서수척도가 생길수 있음
* 따라서, 대소관계가 있는 데이터를 분석할 경우 정확도에 영향을 미칠수 있음
  + = > 원핫인코딩을 사용함으로써 문제해결

# 원핫인코딩 
* 범주값의 유형에 따라 더미변수를 추가해
* 고유값에 해당 컬럼에만 1을 표시하고 나머지는 0으로 표시하는 방식
* 즉, 1차원 데이터를 2차원 데이터롤 변환해서 인코딩을 시행함
```
'티비','냉장고','가스렌지','에어콘','컴퓨터'
1       0        0           0        0
0       1        0           0        0
0       0        1           0        0
0       0        0           1        0
0       0        0           0        1
```
"""

from sklearn.preprocessing import OneHotEncoder

items = ['티비','냉장고','가스렌지','에어콘','컴퓨터']

# 먼저 LabelEncoder 로 문자열을 숫자값으로 변환
encoder = LabelEncoder()
encoder.fit(items)
labels = encoder.transform(items)

# 1차원 데이터를 2차원 데이터로 변환
labels = labels.reshape(-1,1)
# reshape 함수의 -1 : 행을 열로 전환
# 따라서, 1차원을 1행2열의 2차원으로 변환함
print(labels)

# 원핫인코딩 적용
onehot = OneHotEncoder()
onehot.fit(labels)
ohlabels = onehot.transform(labels)

print(ohlabels.shape)     # 원핫인코딩 변환코드 유형
print(ohlabels)           # 실제 변환된 값
print(ohlabels.toarray()) # 변환된 값을 배열로 재변환

# 위에서 보듯 sklearn의 원핫인코딩 API는 사용불편
# 원핫인코딩 전 레이블 인코딩이 선행되어야 함

# pandas의 원핫인코딩 api가 훨씬 편함
# get_dummies 함수 이용
# 단 변환대상은 데이터프레임으로 작성되어 있어야 함
df = pd.DataFrame({'':items})
pd.get_dummies(df)

"""# 특성 스케일링과 표준화/정규화
* 서로 다른 범위, 단위의 변수값을 일정수준으로 맞추는 작업을 특성 스케일링이라 함

+ 어떤 데이터의 값이 정수와 실수가 혼용되어 있거나
+ 값의 범위가 1~100, 0~0.001, 1~1000 등등의 경우 데이터 분석시 많은 cpu 파워/ 
+ 메모리가 필요하고
+ 학습시 느려질 수 있으며 제대로 된 결과가 나오지 않을 수 있음
+ 이것을 제대로 변환하는 방법은 정규화와 표준화가 있음

* StandardScaler : 평균 0, 표준편차 1 로 되도록 변환
* MinMaxScaler : 최소값 0, 최대값 1로 되도록 변환
  + 단 이상치에 영향을 받을 수 있음
"""

from sklearn.datasets import load_boston

pd.set_option('display.float_format',lambda x :'%.2f'%x)
np.set_printoptions(formatter={'float_kind':'{:.3f}'.format})
boston = load_boston()
print(boston.data[:5]) # 실제 bston 데이터의 값과는 달리 표준화 처리가 된 값으로 출력됨

# 표준화 적용 예제
X = np.arange(9,dtype=float) - 3
X = X.reshape(-1,1) # 2차원으로 변환
pd.DataFrame(X).describe()

# StandardScaler 적용
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(X)
xx = scaler.transform(X)
print(xx)
pd.DataFrame(xx).describe()

# MinMaxScaler 적용
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
scaler.fit(X)
xx = scaler.transform(X)
print(xx)
pd.DataFrame(xx).describe()

# boston.csv 의 데이터를 MinMaxScaler와 MinMaxScaler로 표준화/정규화 해보세요
boston2 = pd.read_csv('https://raw.githubusercontent.com/hanrury/machine-learning/master/Boston.csv', sep=',')
print(boston2.head())
print(boston2.describe())

# StandardScaler로 표준화
scaler = StandardScaler()
scaler.fit(boston2)
boston3 = scaler.transform(boston2)
print(boston3[:5])
pd.DataFrame(boston3).describe()

# MinMaxScaler로 표준화
scaler = MinMaxScaler()
scaler.fit(boston2)
boston4 = scaler.transform(boston2)
print(boston4[:5])
pd.DataFrame(boston4).describe()